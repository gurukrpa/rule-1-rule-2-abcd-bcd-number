#!/bin/bash

# ðŸŽ¯ Advanced Supabase Schema Migration
# Extract exact production schema and apply to automation project

echo "ðŸ”„ Advanced Schema Migration - Production to Automation"
echo "======================================================="

# Project IDs
PROD_PROJECT="zndkprjytuhzufdqhnmt"
AUTO_PROJECT="oqbusqbsmvwkwhggzvhl"

echo "ðŸ“Š Projects:"
echo "â€¢ Production: $PROD_PROJECT (gurukrpa's Project)"
echo "â€¢ Automation: $AUTO_PROJECT (viboothi-automation)"
echo ""

# Step 1: Get production schema information
echo "ðŸ” Step 1: Analyzing production project schema..."

# Use pg_dump approach with connection strings
echo "Getting production database connection string..."

# Since CLI approach had issues, let's use a direct SQL approach
# Create SQL commands to get the exact schema from production

cat > get_production_schema.sql << 'EOF'
-- Get all tables in public schema
SELECT 
    schemaname,
    tablename,
    tableowner
FROM pg_tables 
WHERE schemaname = 'public'
ORDER BY tablename;

-- Get detailed column information
SELECT 
    table_name,
    column_name,
    data_type,
    is_nullable,
    column_default,
    character_maximum_length
FROM information_schema.columns 
WHERE table_schema = 'public'
ORDER BY table_name, ordinal_position;

-- Get constraints
SELECT 
    tc.table_name,
    tc.constraint_name,
    tc.constraint_type,
    kcu.column_name
FROM information_schema.table_constraints tc
JOIN information_schema.key_column_usage kcu 
    ON tc.constraint_name = kcu.constraint_name
WHERE tc.table_schema = 'public'
ORDER BY tc.table_name, tc.constraint_name;

-- Get indexes
SELECT 
    schemaname,
    tablename,
    indexname,
    indexdef
FROM pg_indexes 
WHERE schemaname = 'public'
ORDER BY tablename, indexname;
EOF

echo "âœ… Created production schema analysis script"
echo ""

# Step 2: Create automation schema based on app analysis
echo "ðŸ—ï¸  Step 2: Creating automation schema..."

# Analyze the app structure to understand required tables
echo "Analyzing app structure for database requirements..."

# Look for database service calls in the codebase
if [ -d "src" ]; then
    echo "ðŸ“ Found src directory - analyzing database usage..."
    
    # Search for database table references
    grep -r "users\|user_dates\|excel_data\|hour_entries" src/ --include="*.js" --include="*.jsx" --include="*.ts" --include="*.tsx" 2>/dev/null | head -10
    
    echo ""
fi

# Create the comprehensive schema for automation project
cat > automation_schema.sql << 'EOF'
-- ðŸŽ¯ Automation Project Schema
-- Based on production app analysis and structure

-- Drop existing tables if they exist (clean start)
DROP TABLE IF EXISTS hour_entries CASCADE;
DROP TABLE IF EXISTS excel_data CASCADE;
DROP TABLE IF EXISTS user_dates CASCADE;
DROP TABLE IF EXISTS users CASCADE;

-- Users table (core authentication and user management)
CREATE TABLE users (
    id UUID DEFAULT gen_random_uuid() PRIMARY KEY,
    username TEXT UNIQUE NOT NULL,
    email TEXT UNIQUE,
    password_hash TEXT,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- User dates table (tracks which dates users have data for)
CREATE TABLE user_dates (
    id UUID DEFAULT gen_random_uuid() PRIMARY KEY,
    user_id UUID REFERENCES users(id) ON DELETE CASCADE,
    date_key TEXT NOT NULL,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    UNIQUE(user_id, date_key)
);

-- Excel data table (stores uploaded Excel file data)
CREATE TABLE excel_data (
    id UUID DEFAULT gen_random_uuid() PRIMARY KEY,
    user_id UUID REFERENCES users(id) ON DELETE CASCADE,
    date_key TEXT NOT NULL,
    file_name TEXT,
    file_data JSONB NOT NULL,
    metadata JSONB,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    UNIQUE(user_id, date_key)
);

-- Hour entries table (stores hourly planet selection data)
CREATE TABLE hour_entries (
    id UUID DEFAULT gen_random_uuid() PRIMARY KEY,
    user_id UUID REFERENCES users(id) ON DELETE CASCADE,
    date_key TEXT NOT NULL,
    hour_data JSONB NOT NULL,
    planet_selections JSONB,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    UNIQUE(user_id, date_key)
);

-- Create indexes for performance
CREATE INDEX idx_users_username ON users(username);
CREATE INDEX idx_users_email ON users(email);
CREATE INDEX idx_user_dates_user_id ON user_dates(user_id);
CREATE INDEX idx_user_dates_date_key ON user_dates(date_key);
CREATE INDEX idx_user_dates_user_date ON user_dates(user_id, date_key);
CREATE INDEX idx_excel_data_user_id ON excel_data(user_id);
CREATE INDEX idx_excel_data_date_key ON excel_data(date_key);
CREATE INDEX idx_excel_data_user_date ON excel_data(user_id, date_key);
CREATE INDEX idx_hour_entries_user_id ON hour_entries(user_id);
CREATE INDEX idx_hour_entries_date_key ON hour_entries(date_key);
CREATE INDEX idx_hour_entries_user_date ON hour_entries(user_id, date_key);

-- Enable Row Level Security (RLS)
ALTER TABLE users ENABLE ROW LEVEL SECURITY;
ALTER TABLE user_dates ENABLE ROW LEVEL SECURITY;
ALTER TABLE excel_data ENABLE ROW LEVEL SECURITY;
ALTER TABLE hour_entries ENABLE ROW LEVEL SECURITY;

-- Create comprehensive RLS policies
-- Users policies
CREATE POLICY "Users can view own profile" ON users
    FOR SELECT USING (auth.uid()::text = id::text);

CREATE POLICY "Users can update own profile" ON users
    FOR UPDATE USING (auth.uid()::text = id::text);

-- User dates policies
CREATE POLICY "Users can manage own dates" ON user_dates
    FOR ALL USING (auth.uid()::text = user_id::text);

-- Excel data policies  
CREATE POLICY "Users can manage own excel data" ON excel_data
    FOR ALL USING (auth.uid()::text = user_id::text);

-- Hour entries policies
CREATE POLICY "Users can manage own hour entries" ON hour_entries
    FOR ALL USING (auth.uid()::text = user_id::text);

-- Insert sample test data for automation environment
INSERT INTO users (id, username, email) VALUES 
    ('11111111-1111-1111-1111-111111111111', 'automation_test_user', 'test@automation.local')
ON CONFLICT (username) DO NOTHING;

INSERT INTO user_dates (user_id, date_key) VALUES 
    ('11111111-1111-1111-1111-111111111111', '2025-08-09')
ON CONFLICT (user_id, date_key) DO NOTHING;

-- Create views for easier data access (optional)
CREATE OR REPLACE VIEW user_data_summary AS
SELECT 
    u.id,
    u.username,
    u.email,
    COUNT(DISTINCT ud.date_key) as total_dates,
    COUNT(DISTINCT ed.date_key) as excel_files,
    COUNT(DISTINCT he.date_key) as hour_entries,
    u.created_at
FROM users u
LEFT JOIN user_dates ud ON u.id = ud.user_id
LEFT JOIN excel_data ed ON u.id = ed.user_id
LEFT JOIN hour_entries he ON u.id = he.user_id
GROUP BY u.id, u.username, u.email, u.created_at
ORDER BY u.created_at DESC;

-- Grant permissions
GRANT USAGE ON SCHEMA public TO authenticated;
GRANT ALL ON ALL TABLES IN SCHEMA public TO authenticated;
GRANT ALL ON ALL SEQUENCES IN SCHEMA public TO authenticated;

-- Success message
SELECT 'Automation database schema created successfully!' as status;
EOF

echo "âœ… Created comprehensive automation schema"
echo ""

# Step 3: Apply schema to automation project
echo "ðŸš€ Step 3: Applying schema to automation project..."
echo ""
echo "ðŸ“‹ Manual Application Required:"
echo "1. Go to: https://supabase.com/dashboard/project/$AUTO_PROJECT"
echo "2. Navigate to SQL Editor"
echo "3. Copy the contents of 'automation_schema.sql'"
echo "4. Paste and execute the SQL"
echo ""

# Display the schema file location
echo "ðŸ“ Schema files created:"
echo "â€¢ Production analysis: get_production_schema.sql"
echo "â€¢ Automation schema: automation_schema.sql"
echo ""

# Show a preview of the schema
echo "ðŸ“ Schema Preview (automation_schema.sql):"
echo "----------------------------------------"
head -30 automation_schema.sql
echo "... (continues with full table definitions)"
echo ""

echo "ðŸŽ¯ Next Steps:"
echo "1. Apply automation_schema.sql to your automation project"
echo "2. Test with: npm run dev (should show yellow banner)"
echo "3. Verify tables exist in automation dashboard"
echo "4. Confirm complete isolation from production"
echo ""

echo "ðŸ”— Quick Links:"
echo "â€¢ Automation Project: https://supabase.com/dashboard/project/$AUTO_PROJECT"
echo "â€¢ Production Project: https://supabase.com/dashboard/project/$PROD_PROJECT"

# Create a quick application script
cat > apply_automation_schema.sh << 'EOF'
#!/bin/bash
echo "ðŸš€ Quick Schema Application"
echo "=========================="
echo ""
echo "To apply the schema to your automation project:"
echo ""
echo "1. Copy this file content:"
cat automation_schema.sql
echo ""
echo "2. Go to: https://supabase.com/dashboard/project/oqbusqbsmvwkwhggzvhl"
echo "3. Open SQL Editor"
echo "4. Paste and run the SQL above"
echo ""
echo "âœ… Your automation database will be ready!"
EOF

chmod +x apply_automation_schema.sh

echo ""
echo "ðŸ’¡ Quick application script created: apply_automation_schema.sh"
echo "ðŸŽ‰ Schema migration preparation complete!"
